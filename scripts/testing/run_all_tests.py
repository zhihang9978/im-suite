#!/usr/bin/env python3
"""
å¿—èˆªå¯†ä¿¡ç»¼åˆæµ‹è¯•è„šæœ¬
è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼šåŠŸèƒ½æµ‹è¯•ã€æ€§èƒ½æµ‹è¯•ã€å…¼å®¹æ€§æµ‹è¯•ã€ç”¨æˆ·ä½“éªŒæµ‹è¯•
"""

import subprocess
import json
import time
import os
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('comprehensive_test.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ComprehensiveTester:
    """ç»¼åˆæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_results = {}
        self.start_time = None
        self.end_time = None
    
    def run_test_script(self, script_name: str, script_path: str) -> dict:
        """è¿è¡Œå•ä¸ªæµ‹è¯•è„šæœ¬"""
        logger.info(f"å¼€å§‹è¿è¡Œ {script_name}")
        start_time = time.time()
        
        try:
            # è¿è¡Œæµ‹è¯•è„šæœ¬
            result = subprocess.run(
                ["python3", script_path],
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            end_time = time.time()
            duration = end_time - start_time
            
            if result.returncode == 0:
                status = "SUCCESS"
                message = f"{script_name} æ‰§è¡ŒæˆåŠŸ"
            else:
                status = "FAILED"
                message = f"{script_name} æ‰§è¡Œå¤±è´¥: {result.stderr}"
            
            logger.info(f"{script_name} å®Œæˆ: {status} (è€—æ—¶: {duration:.2f}ç§’)")
            
            return {
                "script_name": script_name,
                "status": status,
                "message": message,
                "duration": duration,
                "returncode": result.returncode,
                "stdout": result.stdout,
                "stderr": result.stderr
            }
            
        except subprocess.TimeoutExpired:
            logger.error(f"{script_name} æ‰§è¡Œè¶…æ—¶")
            return {
                "script_name": script_name,
                "status": "TIMEOUT",
                "message": f"{script_name} æ‰§è¡Œè¶…æ—¶",
                "duration": 300,
                "returncode": -1,
                "stdout": "",
                "stderr": "æ‰§è¡Œè¶…æ—¶"
            }
        except Exception as e:
            logger.error(f"{script_name} æ‰§è¡Œå¼‚å¸¸: {e}")
            return {
                "script_name": script_name,
                "status": "ERROR",
                "message": f"{script_name} æ‰§è¡Œå¼‚å¸¸: {str(e)}",
                "duration": 0,
                "returncode": -1,
                "stdout": "",
                "stderr": str(e)
            }
    
    def load_test_report(self, report_file: str) -> dict:
        """åŠ è½½æµ‹è¯•æŠ¥å‘Š"""
        try:
            if os.path.exists(report_file):
                with open(report_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                return {"error": f"æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {report_file}"}
        except Exception as e:
            return {"error": f"åŠ è½½æŠ¥å‘Šå¤±è´¥: {str(e)}"}
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("å¼€å§‹å¿—èˆªå¯†ä¿¡ç»¼åˆæµ‹è¯•")
        logger.info("=" * 60)
        
        self.start_time = datetime.now()
        
        # æµ‹è¯•è„šæœ¬é…ç½®
        test_scripts = [
            {
                "name": "åŠŸèƒ½æµ‹è¯•",
                "path": "scripts/testing/functional_test.py",
                "report": "test_report.json"
            },
            {
                "name": "æ€§èƒ½æµ‹è¯•",
                "path": "scripts/testing/performance_test.py",
                "report": "performance_report.json"
            },
            {
                "name": "å…¼å®¹æ€§æµ‹è¯•",
                "path": "scripts/testing/compatibility_test.py",
                "report": "compatibility_report.json"
            },
            {
                "name": "ç”¨æˆ·ä½“éªŒæµ‹è¯•",
                "path": "scripts/testing/ux_test.py",
                "report": "ux_report.json"
            }
        ]
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        for test_config in test_scripts:
            script_name = test_config["name"]
            script_path = test_config["path"]
            report_file = test_config["report"]
            
            logger.info(f"\n{'='*20} {script_name} {'='*20}")
            
            # è¿è¡Œæµ‹è¯•è„šæœ¬
            test_result = self.run_test_script(script_name, script_path)
            self.test_results[script_name] = test_result
            
            # åŠ è½½æµ‹è¯•æŠ¥å‘Š
            if test_result["status"] == "SUCCESS":
                report_data = self.load_test_report(report_file)
                self.test_results[script_name]["report"] = report_data
                
                # æ˜¾ç¤ºæµ‹è¯•æŠ¥å‘Šæ‘˜è¦
                self.display_test_summary(script_name, report_data)
            else:
                logger.error(f"{script_name} æ‰§è¡Œå¤±è´¥ï¼Œæ— æ³•åŠ è½½æŠ¥å‘Š")
        
        self.end_time = datetime.now()
        
        # ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š
        self.generate_comprehensive_report()
    
    def display_test_summary(self, test_name: str, report_data: dict):
        """æ˜¾ç¤ºæµ‹è¯•æ‘˜è¦"""
        if "error" in report_data:
            logger.error(f"{test_name} æŠ¥å‘ŠåŠ è½½å¤±è´¥: {report_data['error']}")
            return
        
        if test_name == "åŠŸèƒ½æµ‹è¯•":
            summary = report_data.get("summary", {})
            logger.info(f"  æ€»æµ‹è¯•æ•°: {summary.get('total_tests', 0)}")
            logger.info(f"  é€šè¿‡æµ‹è¯•: {summary.get('passed_tests', 0)}")
            logger.info(f"  å¤±è´¥æµ‹è¯•: {summary.get('failed_tests', 0)}")
            logger.info(f"  é€šè¿‡ç‡: {summary.get('pass_rate', 0):.2f}%")
        
        elif test_name == "æ€§èƒ½æµ‹è¯•":
            system_info = report_data.get("system_info", {})
            logger.info(f"  CPUä½¿ç”¨ç‡: {system_info.get('cpu_usage', 0):.2f}%")
            logger.info(f"  å†…å­˜ä½¿ç”¨: {system_info.get('memory_usage', 0):.2f}MB")
            logger.info(f"  ç£ç›˜ä½¿ç”¨: {system_info.get('disk_usage', 0):.2f}GB")
        
        elif test_name == "å…¼å®¹æ€§æµ‹è¯•":
            summary = report_data.get("summary", {})
            logger.info(f"  æ€»æµ‹è¯•æ•°: {summary.get('total_tests', 0)}")
            logger.info(f"  é€šè¿‡æµ‹è¯•: {summary.get('passed_tests', 0)}")
            logger.info(f"  é€šè¿‡ç‡: {summary.get('pass_rate', 0):.2f}%")
            
            brand_stats = report_data.get("brand_stats", {})
            logger.info("  å“ç‰Œå…¼å®¹æ€§:")
            for brand, stats in brand_stats.items():
                brand_pass_rate = (stats["passed"] / stats["total"]) * 100 if stats["total"] > 0 else 0
                logger.info(f"    {brand}: {stats['passed']}/{stats['total']} ({brand_pass_rate:.1f}%)")
        
        elif test_name == "ç”¨æˆ·ä½“éªŒæµ‹è¯•":
            summary = report_data.get("summary", {})
            logger.info(f"  æµ‹è¯•å“ç‰Œæ•°: {summary.get('total_brands', 0)}")
            logger.info(f"  å¹³å‡å¾—åˆ†: {summary.get('average_score', 0):.1f}/100")
            logger.info(f"  æœ€é«˜å¾—åˆ†: {summary.get('highest_score', 0):.1f}/100")
            logger.info(f"  æœ€ä½å¾—åˆ†: {summary.get('lowest_score', 0):.1f}/100")
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        total_duration = (self.end_time - self.start_time).total_seconds()
        
        logger.info("\n" + "=" * 60)
        logger.info("ç»¼åˆæµ‹è¯•æŠ¥å‘Š")
        logger.info("=" * 60)
        logger.info(f"æµ‹è¯•å¼€å§‹æ—¶é—´: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"æµ‹è¯•ç»“æŸæ—¶é—´: {self.end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"æ€»è€—æ—¶: {total_duration:.2f}ç§’")
        
        # ç»Ÿè®¡æµ‹è¯•ç»“æœ
        total_tests = len(self.test_results)
        successful_tests = sum(1 for result in self.test_results.values() if result["status"] == "SUCCESS")
        failed_tests = sum(1 for result in self.test_results.values() if result["status"] == "FAILED")
        error_tests = sum(1 for result in self.test_results.values() if result["status"] == "ERROR")
        timeout_tests = sum(1 for result in self.test_results.values() if result["status"] == "TIMEOUT")
        
        logger.info(f"\næµ‹è¯•ç»Ÿè®¡:")
        logger.info(f"  æ€»æµ‹è¯•æ•°: {total_tests}")
        logger.info(f"  æˆåŠŸæµ‹è¯•: {successful_tests}")
        logger.info(f"  å¤±è´¥æµ‹è¯•: {failed_tests}")
        logger.info(f"  é”™è¯¯æµ‹è¯•: {error_tests}")
        logger.info(f"  è¶…æ—¶æµ‹è¯•: {timeout_tests}")
        logger.info(f"  æˆåŠŸç‡: {(successful_tests/total_tests)*100:.2f}%")
        
        # è¯¦ç»†æµ‹è¯•ç»“æœ
        logger.info(f"\nè¯¦ç»†æµ‹è¯•ç»“æœ:")
        for test_name, result in self.test_results.items():
            status_icon = "âœ…" if result["status"] == "SUCCESS" else "âŒ"
            logger.info(f"  {status_icon} {test_name}: {result['status']} (è€—æ—¶: {result['duration']:.2f}ç§’)")
            if result["status"] != "SUCCESS":
                logger.info(f"    é”™è¯¯ä¿¡æ¯: {result['message']}")
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Šæ•°æ®
        comprehensive_report = {
            "test_info": {
                "start_time": self.start_time.isoformat(),
                "end_time": self.end_time.isoformat(),
                "total_duration": total_duration
            },
            "summary": {
                "total_tests": total_tests,
                "successful_tests": successful_tests,
                "failed_tests": failed_tests,
                "error_tests": error_tests,
                "timeout_tests": timeout_tests,
                "success_rate": (successful_tests/total_tests)*100 if total_tests > 0 else 0
            },
            "test_results": self.test_results
        }
        
        # ä¿å­˜ç»¼åˆæŠ¥å‘Š
        with open('comprehensive_test_report.json', 'w', encoding='utf-8') as f:
            json.dump(comprehensive_report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\nç»¼åˆæµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: comprehensive_test_report.json")
        
        # ç”Ÿæˆæµ‹è¯•å»ºè®®
        self.generate_test_recommendations()
    
    def generate_test_recommendations(self):
        """ç”Ÿæˆæµ‹è¯•å»ºè®®"""
        logger.info(f"\næµ‹è¯•å»ºè®®:")
        
        # åˆ†ææµ‹è¯•ç»“æœ
        failed_tests = [name for name, result in self.test_results.items() if result["status"] != "SUCCESS"]
        
        if not failed_tests:
            logger.info("  ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼ç³»ç»Ÿè¿è¡Œè‰¯å¥½ã€‚")
        else:
            logger.info(f"  âš ï¸  ä»¥ä¸‹æµ‹è¯•éœ€è¦å…³æ³¨:")
            for test_name in failed_tests:
                logger.info(f"    - {test_name}: éœ€è¦ä¿®å¤ç›¸å…³é—®é¢˜")
        
        # æ€§èƒ½å»ºè®®
        performance_result = self.test_results.get("æ€§èƒ½æµ‹è¯•", {})
        if performance_result.get("status") == "SUCCESS":
            performance_report = performance_result.get("report", {})
            system_info = performance_report.get("system_info", {})
            
            if system_info.get("cpu_usage", 0) > 80:
                logger.info("  ğŸ’¡ CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–æ€§èƒ½")
            if system_info.get("memory_usage", 0) > 1000:
                logger.info("  ğŸ’¡ å†…å­˜ä½¿ç”¨è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–å†…å­˜ç®¡ç†")
        
        # å…¼å®¹æ€§å»ºè®®
        compatibility_result = self.test_results.get("å…¼å®¹æ€§æµ‹è¯•", {})
        if compatibility_result.get("status") == "SUCCESS":
            compatibility_report = compatibility_result.get("report", {})
            summary = compatibility_report.get("summary", {})
            
            if summary.get("pass_rate", 0) < 90:
                logger.info("  ğŸ’¡ å…¼å®¹æ€§æµ‹è¯•é€šè¿‡ç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–å“ç‰Œé€‚é…")
        
        # ç”¨æˆ·ä½“éªŒå»ºè®®
        ux_result = self.test_results.get("ç”¨æˆ·ä½“éªŒæµ‹è¯•", {})
        if ux_result.get("status") == "SUCCESS":
            ux_report = ux_result.get("report", {})
            summary = ux_report.get("summary", {})
            
            if summary.get("average_score", 0) < 80:
                logger.info("  ğŸ’¡ ç”¨æˆ·ä½“éªŒå¾—åˆ†è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–ç•Œé¢å’Œäº¤äº’")

def main():
    """ä¸»å‡½æ•°"""
    tester = ComprehensiveTester()
    tester.run_all_tests()

if __name__ == "__main__":
    main()
